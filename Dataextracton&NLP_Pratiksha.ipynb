{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvftQLFzxjXGkL/VSwHyj9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pratikshathorat96/Data-Extraction-and-NLP/blob/main/Dataextracton%26NLP_Pratiksha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Extraction and NLP for **Blackcoffer**"
      ],
      "metadata": {
        "id": "5nexN9SGmZuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project By - Pratiksha Thorat"
      ],
      "metadata": {
        "id": "N5sZ2U4CvqAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output link to Google Drive** - https://docs.google.com/spreadsheets/d/1ikjquITX32sNksW8R6tx30tBCdFz0fGK/edit?usp=sharing&ouid=113051524455290143470&rtpof=true&sd=true"
      ],
      "metadata": {
        "id": "gNX9OZWTvvPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objective"
      ],
      "metadata": {
        "id": "VNIZMlpmtGM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective of this document is to explain methodology adopted to perform text analysis to drive sentimental opinion, sentiment scores, readability, passive words, personal pronouns and etc."
      ],
      "metadata": {
        "id": "SHGdabHFtyRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary"
      ],
      "metadata": {
        "id": "nuIZNRZ6t0ro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project involves extracting textual data from a set of URLs provided in an input Excel file and performing text analysis to compute various variables. The objective is to extract article text from the URLs, clean the text, and analyze it to calculate sentiment scores, readability metrics, and other textual variables.\n",
        "\n",
        "Here's an overview of the key components and steps involved:\n",
        "\n",
        "1. Data Extraction: Python code is developed to extract article text from the URLs provided in the input Excel file. Libraries such as requests and BeautifulSoup are used for web scraping. The extracted text is cleaned to remove unnecessary elements such as HTML tags, punctuation, and stopwords.\n",
        "\n",
        "2. Text Analysis: The cleaned text is subjected to text analysis to compute various variables. This includes sentiment analysis to determine positive and negative scores, polarity score, and subjectivity score using the TextBlob library. Readability metrics such as average sentence length, percentage of complex words, and Fog index are calculated. Additionally, the count of personal pronouns and the average word length are computed.\n",
        "\n",
        "3. Output Generation: The computed variables are structured according to the required output format specified in an output Excel file. The output includes URL IDs, URLs, sentiment scores, readability metrics, and other textual variables.\n",
        "\n",
        "4. Code Implementation: Python code is developed to automate the entire process. Libraries such as NLTK (Natural Language Toolkit) are utilized for text preprocessing tasks such as tokenization, stemming, and syllable counting. The output is generated as a new Excel file containing the computed variables.\n",
        "\n",
        "Overall, the project involves a combination of web scraping, text preprocessing, sentiment analysis, and readability analysis techniques to extract and analyze textual data from URLs and generate structured output for further analysis or reporting. The code is designed to be modular and scalable, allowing for easy adaptation to different sets of URLs and analytical requirements."
      ],
      "metadata": {
        "id": "TOjNQN9Rt9Sw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's Begin"
      ],
      "metadata": {
        "id": "xWgpoOycu4fg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrD7yL_HjnU9",
        "outputId": "9175a59d-e4cf-4191-b6e7-ee265eac7030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: textstat in /usr/local/lib/python3.10/dist-packages (0.7.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.10/dist-packages (from textstat) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 nltk textstat  # Install required libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "jwxAkO9ZrCq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5p4ebigrKRR",
        "outputId": "1fb12434-2db8-436e-d3a0-c282a6b4611f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract article text from URL\n",
        "def extract_text_from_url(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        # Assuming article text is enclosed in <p> tags\n",
        "        article_text = ' '.join([p.get_text() for p in soup.find_all('p')])\n",
        "        return article_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from URL: {url}\")\n",
        "        print(e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "EXzFKGkErNCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    # Tokenize text\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove punctuation\n",
        "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if not word in stop_words]\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "    # Join tokens back into text\n",
        "    cleaned_text = ' '.join(tokens)\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "CDtYPe1jrQp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate readability metrics\n",
        "def calculate_readability(text):\n",
        "    # Average sentence length\n",
        "    sentences = sent_tokenize(text)\n",
        "    num_sentences = len(sentences)\n",
        "    words_per_sentence = len(word_tokenize(text)) / num_sentences\n",
        "\n",
        "    # Percentage of complex words\n",
        "    words = [word for word in text.split() if word.isalpha()]\n",
        "    complex_words = [word for word in words if count_syllables(word) > 2]\n",
        "    percentage_complex_words = (len(complex_words) / len(words)) * 100\n",
        "\n",
        "    # Fog Index\n",
        "    fog_index = 0.4 * (words_per_sentence + percentage_complex_words)\n",
        "\n",
        "    return words_per_sentence, percentage_complex_words, fog_index"
      ],
      "metadata": {
        "id": "5I15N14GrT3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to count syllables\n",
        "def count_syllables(word):\n",
        "    return max(1, len([char for char in word if char.lower() in 'aeiou']))\n",
        "\n",
        "# Function to count personal pronouns\n",
        "def count_personal_pronouns(text):\n",
        "    personal_pronouns = re.findall(r'\\b(I|we|my|ours|us)\\b', text)\n",
        "    return len(personal_pronouns)"
      ],
      "metadata": {
        "id": "0JzOFLiNrXZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate average word length\n",
        "def calculate_avg_word_length(text):\n",
        "    words = word_tokenize(text)\n",
        "    total_chars = sum(len(word) for word in words)\n",
        "    avg_word_length = total_chars / len(words)\n",
        "    return avg_word_length"
      ],
      "metadata": {
        "id": "j_FJWbgxraGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform sentiment analysis\n",
        "def perform_sentiment_analysis(text):\n",
        "    blob = TextBlob(text)\n",
        "    sentiment = blob.sentiment\n",
        "    positive_score = sum(1 for sentence in blob.sentences if sentence.sentiment.polarity > 0)\n",
        "    negative_score = sum(1 for sentence in blob.sentences if sentence.sentiment.polarity < 0)\n",
        "    polarity_score = sentiment.polarity\n",
        "    subjectivity_score = sentiment.subjectivity\n",
        "    return positive_score, negative_score, polarity_score, subjectivity_score"
      ],
      "metadata": {
        "id": "oRFo1CCLrdFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read input Excel file\n",
        "input_df = pd.read_excel('/content/Input.xlsx')"
      ],
      "metadata": {
        "id": "93B5lKborftx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over each row in the input dataframe\n",
        "output_data = []\n",
        "for index, row in input_df.iterrows():\n",
        "    url = row['URL']\n",
        "    url_id = row['URL_ID']\n",
        "    article_text = extract_text_from_url(url)\n",
        "    if article_text:\n",
        "        cleaned_text = clean_text(article_text)\n",
        "        words_per_sentence, percentage_complex_words, fog_index = calculate_readability(cleaned_text)\n",
        "        complex_word_count = len([word for word in cleaned_text.split() if count_syllables(word) > 2])\n",
        "        word_count = len(cleaned_text.split())\n",
        "        syllables_per_word = sum(count_syllables(word) for word in cleaned_text.split()) / len(cleaned_text.split())\n",
        "        personal_pronouns_count = count_personal_pronouns(article_text)\n",
        "        avg_word_length = calculate_avg_word_length(article_text)\n",
        "        positive_score, negative_score, polarity_score, subjectivity_score = perform_sentiment_analysis(cleaned_text)\n",
        "\n",
        "        # Append results to output data list\n",
        "        output_data.append([url_id, url, positive_score, negative_score, polarity_score, subjectivity_score,\n",
        "                            words_per_sentence, percentage_complex_words, fog_index, words_per_sentence,\n",
        "                            complex_word_count, word_count, syllables_per_word,\n",
        "                            personal_pronouns_count, avg_word_length])"
      ],
      "metadata": {
        "id": "iwJO7ZwYrkmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create output dataframe\n",
        "output_df = pd.DataFrame(output_data, columns=['URL_ID', 'URL', 'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE',\n",
        "                                               'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH', 'PERCENTAGE OF COMPLEX WORDS',\n",
        "                                               'FOG INDEX', 'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT',\n",
        "                                               'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH'])\n"
      ],
      "metadata": {
        "id": "JBPr5EGXrn-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_df.info() # checking for the all info & variables in dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgE5YqtPsyYA",
        "outputId": "e1e2f485-4e17-4afa-8431-e662346208f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 15 columns):\n",
            " #   Column                            Non-Null Count  Dtype  \n",
            "---  ------                            --------------  -----  \n",
            " 0   URL_ID                            100 non-null    object \n",
            " 1   URL                               100 non-null    object \n",
            " 2   POSITIVE SCORE                    100 non-null    int64  \n",
            " 3   NEGATIVE SCORE                    100 non-null    int64  \n",
            " 4   POLARITY SCORE                    100 non-null    float64\n",
            " 5   SUBJECTIVITY SCORE                100 non-null    float64\n",
            " 6   AVG SENTENCE LENGTH               100 non-null    float64\n",
            " 7   PERCENTAGE OF COMPLEX WORDS       100 non-null    float64\n",
            " 8   FOG INDEX                         100 non-null    float64\n",
            " 9   AVG NUMBER OF WORDS PER SENTENCE  100 non-null    float64\n",
            " 10  COMPLEX WORD COUNT                100 non-null    int64  \n",
            " 11  WORD COUNT                        100 non-null    int64  \n",
            " 12  SYLLABLE PER WORD                 100 non-null    float64\n",
            " 13  PERSONAL PRONOUNS                 100 non-null    int64  \n",
            " 14  AVG WORD LENGTH                   100 non-null    float64\n",
            "dtypes: float64(8), int64(5), object(2)\n",
            "memory usage: 11.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df.describe() # short overview of data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "UcN585A3s2pA",
        "outputId": "3a41b3ff-6ebc-4318-9a64-61d99df5e08f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
              "count      100.000000      100.000000      100.000000          100.000000   \n",
              "mean         0.870000        0.130000        0.072109            0.358864   \n",
              "std          0.337998        0.337998        0.077283            0.067278   \n",
              "min          0.000000        0.000000       -0.201276            0.160476   \n",
              "25%          1.000000        0.000000        0.036571            0.328083   \n",
              "50%          1.000000        0.000000        0.068836            0.361099   \n",
              "75%          1.000000        0.000000        0.104471            0.392872   \n",
              "max          1.000000        1.000000        0.406108            0.622491   \n",
              "\n",
              "       AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS   FOG INDEX  \\\n",
              "count           100.000000                   100.000000  100.000000   \n",
              "mean            704.600000                    26.469823  292.427929   \n",
              "std             309.509485                     3.444680  123.579366   \n",
              "min             146.000000                    20.034101   70.728767   \n",
              "25%             501.500000                    23.940183  210.948207   \n",
              "50%             720.000000                    26.070335  299.139875   \n",
              "75%             904.250000                    29.403897  371.609604   \n",
              "max            2052.000000                    35.920177  831.560234   \n",
              "\n",
              "       AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT   WORD COUNT  \\\n",
              "count                        100.000000           100.00000   100.000000   \n",
              "mean                         704.600000           184.73000   704.600000   \n",
              "std                          309.509485            84.25105   309.509485   \n",
              "min                          146.000000            45.00000   146.000000   \n",
              "25%                          501.500000           125.25000   501.500000   \n",
              "50%                          720.000000           182.50000   720.000000   \n",
              "75%                          904.250000           232.00000   904.250000   \n",
              "max                         2052.000000           552.00000  2052.000000   \n",
              "\n",
              "       SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
              "count         100.000000         100.000000       100.000000  \n",
              "mean            2.171523           6.370000         4.863712  \n",
              "std             0.076307           5.868345         0.294740  \n",
              "min             1.984330           1.000000         4.273816  \n",
              "25%             2.114487           2.000000         4.630254  \n",
              "50%             2.161977           5.000000         4.849509  \n",
              "75%             2.227163           8.000000         5.047494  \n",
              "max             2.398214          33.000000         5.594937  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41b319b8-eda5-4d1a-bb46-08192878c7c8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>POSITIVE SCORE</th>\n",
              "      <th>NEGATIVE SCORE</th>\n",
              "      <th>POLARITY SCORE</th>\n",
              "      <th>SUBJECTIVITY SCORE</th>\n",
              "      <th>AVG SENTENCE LENGTH</th>\n",
              "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
              "      <th>FOG INDEX</th>\n",
              "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
              "      <th>COMPLEX WORD COUNT</th>\n",
              "      <th>WORD COUNT</th>\n",
              "      <th>SYLLABLE PER WORD</th>\n",
              "      <th>PERSONAL PRONOUNS</th>\n",
              "      <th>AVG WORD LENGTH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.00000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.870000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>0.072109</td>\n",
              "      <td>0.358864</td>\n",
              "      <td>704.600000</td>\n",
              "      <td>26.469823</td>\n",
              "      <td>292.427929</td>\n",
              "      <td>704.600000</td>\n",
              "      <td>184.73000</td>\n",
              "      <td>704.600000</td>\n",
              "      <td>2.171523</td>\n",
              "      <td>6.370000</td>\n",
              "      <td>4.863712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.337998</td>\n",
              "      <td>0.337998</td>\n",
              "      <td>0.077283</td>\n",
              "      <td>0.067278</td>\n",
              "      <td>309.509485</td>\n",
              "      <td>3.444680</td>\n",
              "      <td>123.579366</td>\n",
              "      <td>309.509485</td>\n",
              "      <td>84.25105</td>\n",
              "      <td>309.509485</td>\n",
              "      <td>0.076307</td>\n",
              "      <td>5.868345</td>\n",
              "      <td>0.294740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.201276</td>\n",
              "      <td>0.160476</td>\n",
              "      <td>146.000000</td>\n",
              "      <td>20.034101</td>\n",
              "      <td>70.728767</td>\n",
              "      <td>146.000000</td>\n",
              "      <td>45.00000</td>\n",
              "      <td>146.000000</td>\n",
              "      <td>1.984330</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.273816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036571</td>\n",
              "      <td>0.328083</td>\n",
              "      <td>501.500000</td>\n",
              "      <td>23.940183</td>\n",
              "      <td>210.948207</td>\n",
              "      <td>501.500000</td>\n",
              "      <td>125.25000</td>\n",
              "      <td>501.500000</td>\n",
              "      <td>2.114487</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.630254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.068836</td>\n",
              "      <td>0.361099</td>\n",
              "      <td>720.000000</td>\n",
              "      <td>26.070335</td>\n",
              "      <td>299.139875</td>\n",
              "      <td>720.000000</td>\n",
              "      <td>182.50000</td>\n",
              "      <td>720.000000</td>\n",
              "      <td>2.161977</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.849509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.104471</td>\n",
              "      <td>0.392872</td>\n",
              "      <td>904.250000</td>\n",
              "      <td>29.403897</td>\n",
              "      <td>371.609604</td>\n",
              "      <td>904.250000</td>\n",
              "      <td>232.00000</td>\n",
              "      <td>904.250000</td>\n",
              "      <td>2.227163</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.047494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.406108</td>\n",
              "      <td>0.622491</td>\n",
              "      <td>2052.000000</td>\n",
              "      <td>35.920177</td>\n",
              "      <td>831.560234</td>\n",
              "      <td>2052.000000</td>\n",
              "      <td>552.00000</td>\n",
              "      <td>2052.000000</td>\n",
              "      <td>2.398214</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>5.594937</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41b319b8-eda5-4d1a-bb46-08192878c7c8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-41b319b8-eda5-4d1a-bb46-08192878c7c8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-41b319b8-eda5-4d1a-bb46-08192878c7c8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-39bba90b-a787-4a3d-a9da-918101ee8c6b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-39bba90b-a787-4a3d-a9da-918101ee8c6b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-39bba90b-a787-4a3d-a9da-918101ee8c6b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"output_df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"POSITIVE SCORE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35.094323504632236,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.87,\n          1.0,\n          0.33799766898963113\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NEGATIVE SCORE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35.28286071887957,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.13,\n          1.0,\n          0.33799766898963113\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POLARITY SCORE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35.3272279507747,\n        \"min\": -0.20127584340946392,\n        \"max\": 100.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.07210884761980801,\n          0.06883605040908412,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SUBJECTIVITY SCORE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 35.24000096799589,\n        \"min\": 0.06727806047479976,\n        \"max\": 100.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.3588637775046376,\n          0.36109886573353017,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AVG SENTENCE LENGTH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 623.9915431650454,\n        \"min\": 100.0,\n        \"max\": 2052.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          704.6,\n          720.0,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PERCENTAGE OF COMPLEX WORDS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.59727461787314,\n        \"min\": 3.444679926419798,\n        \"max\": 100.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          26.469823196900364,\n          26.070334712412215,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FOG INDEX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 244.39777395954755,\n        \"min\": 70.72876712328768,\n        \"max\": 831.5602339181287,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          292.42792927876013,\n          299.1398748840179,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AVG NUMBER OF WORDS PER SENTENCE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 623.9915431650454,\n        \"min\": 100.0,\n        \"max\": 2052.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          704.6,\n          720.0,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"COMPLEX WORD COUNT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 159.1795820424138,\n        \"min\": 45.0,\n        \"max\": 552.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          184.73,\n          182.5,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WORD COUNT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 623.9915431650454,\n        \"min\": 100.0,\n        \"max\": 2052.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          704.6,\n          720.0,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SYLLABLE PER WORD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 34.69994441243933,\n        \"min\": 0.07630715015914209,\n        \"max\": 100.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2.1715230687530043,\n          2.161977487070277,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PERSONAL PRONOUNS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.82367911387236,\n        \"min\": 1.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          6.37,\n          5.0,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AVG WORD LENGTH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.90259315174643,\n        \"min\": 0.2947404133097759,\n        \"max\": 100.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4.863711920938684,\n          4.849508883432039,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write output to Excel file\n",
        "output_df.to_excel('/content/OutputDF_by_Pratiksh_Thorat.xlsx', index=False)"
      ],
      "metadata": {
        "id": "ms3RKsvXr7jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "3irZa1SJvgk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion, the assignment successfully achieved its objective of extracting textual data from provided URLs and conducting comprehensive text analysis to compute various variables. The project demonstrated proficiency in web scraping techniques using libraries such as requests and BeautifulSoup to extract article text from websites.\n",
        "\n",
        "Furthermore, the implementation of text analysis involved preprocessing techniques such as tokenization, stemming, and stop word removal using the NLTK library. Sentiment analysis using TextBlob provided insights into the sentiment polarity and subjectivity of the extracted text. Additionally, readability metrics such as average sentence length, percentage of complex words, and Fog index were calculated to assess the readability of the text.\n",
        "\n",
        "The assignment showcased the ability to automate the entire process through Python programming, ensuring efficiency and scalability for analyzing large datasets. The generated output, structured according to the specified format, provides valuable insights into the textual content of the articles, facilitating further analysis or decision-making processes.\n",
        "\n",
        "Overall, the assignment demonstrated proficiency in web scraping, text preprocessing, sentiment analysis, and readability analysis, showcasing the capability to extract meaningful information from textual data sourced from the web. The project underscores the importance of leveraging programming and computational techniques to derive insights from unstructured data sources, contributing to informed decision-making and data-driven strategies."
      ],
      "metadata": {
        "id": "RsXKRsUvviQH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thank you so much for reaching end 😀"
      ],
      "metadata": {
        "id": "ErpKvG8lyzLe"
      }
    }
  ]
}